{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e97bb32-5f24-4bd6-9671-e2c0439f3077",
   "metadata": {},
   "source": [
    "<h1>Fashion-MNIST Project </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ffda4-2175-40fd-b78b-6f5719c51a11",
   "metadata": {},
   "source": [
    "<h4>Project Overview\n",
    "<h4p\n",
    "\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782e46b-7300-4e01-8923-f59a7a05dd68",
   "metadata": {},
   "source": [
    "<p>This project will guide you through building a convolutional neural network (CNN) to classify images from the Fashion MNIST dataset using PyTorch. We'll learn how to:</p>\n",
    "<ol>\n",
    "    <li>Load and preprocess the Fashion MNIST dataset</li>\n",
    "    <li>Create a custom Dataset class</li>\n",
    "    <li>Build a CNN model with PyTorch</li>\n",
    "    <li>Train and evaluate the model</li>\n",
    "    <li>Visualize the results</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b7f26-c3be-477b-ad7e-7c3d36171510",
   "metadata": {},
   "source": [
    "<h3>Environment Setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3acda9b-2494-4d6f-87aa-da2d9cb5284f",
   "metadata": {},
   "source": [
    "First, let's install the required packages:\n",
    "<ul>\n",
    "    <li>PyTorch: For building and training neural networks</li>\n",
    "    <li>Torchvision: For computer vision datasets and transformations</li>\n",
    "    <li>Matplotlib: For visualizing images and results</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c81c6-3fde-41a4-a724-0a1517a56c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1909192-c383-4921-8a14-38b36583366b",
   "metadata": {},
   "source": [
    "<h3>Import Necessary Modules</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf39426-7245-44e7-a98e-f12221e4a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e51453-c52f-4b13-90b1-ac02cbfef521",
   "metadata": {},
   "source": [
    "<h3>Prepare the Dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615887f1-7c45-4d28-a38c-68fa3f417dfa",
   "metadata": {},
   "source": [
    "<h4>Understanding the Dataset</h4>\n",
    "<p>Fashion MNIST is a dataset of Zalando's article images consisting of:</p>\n",
    "<ul>\n",
    "    <li>60,000 training examples</li>\n",
    "    <li>10,000 test examples</li>\n",
    "    <li>10 classes (T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot)</li>\n",
    "    <li>28x28 grayscale images</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e1566-1a51-4df8-a7ee-f074f127902c",
   "metadata": {},
   "source": [
    "<p>Let's define a function to visualize samples:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d4dcaa-220e-48f6-ba4d-47ce991f3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title('Class: ' + str(data_sample[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb2182-90b6-4854-9d22-bc414a4fd630",
   "metadata": {},
   "source": [
    "<h4>Creating Dataset Objects</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce6ebc-af38-4bb9-8d1c-465b0b4e9860",
   "metadata": {},
   "source": [
    "<p>We'll create a custom Dataset class with transformations:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f3ed6-fe46-4cef-95ff-cea12b4059b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and transformations\n",
    "IMAGE_SIZE = 16\n",
    "\n",
    "composed = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # Resize images\n",
    "    transforms.ToTensor()  # Convert to tensor\n",
    "])\n",
    "\n",
    "# Create training and validation datasets\n",
    "dataset_train = dsets.FashionMNIST(\n",
    "    root='.fashion/data',\n",
    "    train=True,\n",
    "    transform=composed,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "dataset_val = dsets.FashionMNIST(\n",
    "    root='.fashion/data',\n",
    "    train=False,\n",
    "    transform=composed,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1722fc-1064-4fc4-8bf3-f0425499ea90",
   "metadata": {},
   "source": [
    "<h4>Visualizing Samples</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92942e34-14ba-4484-87d6-764a33282e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 3 samples\n",
    "for n, data_sample in enumerate(dataset_val):\n",
    "    show_data(data_sample)\n",
    "    plt.show()\n",
    "    if n == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651555bb-4f07-4a92-9e84-99295adf1936",
   "metadata": {},
   "source": [
    "<h3>Create Data Loaders</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764beb2b-75bc-4872-b04e-c9ce8de3f138",
   "metadata": {},
   "source": [
    "<p>Data loaders help batch and shuffle our data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e7e14-444d-444b-bc56-e8cf14d8b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e082e6-9a08-493d-b75b-f8b41d92009e",
   "metadata": {},
   "source": [
    "<h3>Building the CNN Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918cd78-7eb3-4faa-a02d-c4f1dead7b42",
   "metadata": {},
   "source": [
    "<p>We'll create a CNN with:</p>\n",
    "<ul>\n",
    "    <li>Two convolutional layers</li>\n",
    "    <li>Batch normalization</li>\n",
    "    <li>Max pooling</li>\n",
    "    <li>Fully connected layer</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d92375-f992-4bf0-9acd-bab2d8756a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_batch(nn.Module):\n",
    "    def __init__(self, out_1=16, out_2=32, num_classes=10):\n",
    "        super(CNN_batch, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
    "        self.conv1_bn = nn.BatchNorm2d(out_1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2_bn = nn.BatchNorm2d(out_2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(out_2 * 4 * 4, num_classes)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = self.conv1_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.cnn2(x)\n",
    "        x = self.conv2_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn_fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabd51c4-de21-4895-a6d3-7b674a4951ec",
   "metadata": {},
   "source": [
    "<h3> Initialize Model and Optimizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba55f2f-2b8f-459d-aae0-145af6b7fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "model = CNN_batch(out_1=16, out_2=32, number_of_classes=10)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff14c38-248d-41a1-9ff2-1f50f251a4c7",
   "metadata": {},
   "source": [
    "<h3>Train the Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada1991-b24d-4458-be5b-fe10a4436a38",
   "metadata": {},
   "source": [
    "<p>Now let's train our model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6c9e6-bcb8-4e5a-ab9a-722cfc96fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Track training progress\n",
    "cost_list = []\n",
    "accuracy_list = []\n",
    "N_test = len(dataset_val)\n",
    "n_epochs = 5\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    cost = 0\n",
    "    model.train()\n",
    "    \n",
    "    # Training loop\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cost += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    for x_test, y_test in test_loader:\n",
    "        z = model(x_test)\n",
    "        _, yhat = torch.max(z.data, 1)\n",
    "        correct += (yhat == y_test).sum().item()\n",
    "    \n",
    "    accuracy = correct / N_test\n",
    "    accuracy_list.append(accuracy)\n",
    "    cost_list.append(cost)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Cost: {cost:.2f}, Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "print(f\"Training completed in {time.time()-start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc44244-f367-49bf-8c38-aa17a0d0cf44",
   "metadata": {},
   "source": [
    "<h3>Visualizing Results</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d35b1-0fc7-400b-8889-3b764ed5554d",
   "metadata": {},
   "source": [
    "<p>Let's plot the training cost and accuracy:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62055c3-42da-493b-b022-6a71d7f83e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training cost\n",
    "plt.plot(cost_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Training Cost Over Time')\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(accuracy_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e208e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:red'\n",
    "ax1.plot(cost_list, color=color)\n",
    "ax1.set_xlabel('epoch', color=color)\n",
    "ax1.set_ylabel('Cost', color=color)\n",
    "ax1.tick_params(axis='y', color=color)\n",
    "    \n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color) \n",
    "ax2.set_xlabel('epoch', color=color)\n",
    "ax2.plot( accuracy_list, color=color)\n",
    "ax2.tick_params(axis='y', color=color)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd9334-a17f-409c-8835-8bc35993db2f",
   "metadata": {},
   "source": [
    "<h3>Testing the Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2b8fca-4e36-47c2-b6bd-8d93b11d1740",
   "metadata": {},
   "source": [
    "<p>Let's test our model on some validation samples:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f45f4dd-70e2-4b0f-8405-ab835e124d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get a batch of test data\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# Make predictions\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Plot some results\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.imshow(images[i].cpu().numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
    "    ax.set_title(f'Pred: {predicted[i].item()}\\nTrue: {labels[i].item()}')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42407aed-11d9-4172-a70a-3972d378b7bb",
   "metadata": {},
   "source": [
    "<h3>Improving the Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d2efb-4516-475c-b9c0-3555292858fb",
   "metadata": {},
   "source": [
    "<p>Here are some ways to potentially improve performance:</p>\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <b>Increase model complexity:</b>\n",
    "    <ul>\n",
    "      <li>Add more convolutional layers</li>\n",
    "      <li>Increase number of filters</li>\n",
    "      <li>Add dropout layers</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <b>Adjust training parameters:</b>\n",
    "    <ul>\n",
    "      <li>Try different learning rates</li>\n",
    "      <li>Increase number of epochs</li>\n",
    "      <li>Use learning rate scheduling</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <b>Data augmentation:</b>\n",
    "    <ul>\n",
    "      <li>Add random rotations/flips</li>\n",
    "      <li>Adjust brightness/contrast</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ol>\n",
    "\n",
    "<p>Example with data augmentation:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d17a23-8a19-4e9d-9a86-8d0f9ac6e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New transforms with augmentation\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Reload datasets with augmentation\n",
    "dataset_train_aug = dsets.FashionMNIST(\n",
    "    root='.fashion/data',\n",
    "    train=True,\n",
    "    transform=augmented_transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ccc70c-c773-4384-a9d3-46aa832bce9e",
   "metadata": {},
   "source": [
    "<h3>Saving and Loading the Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49465de-ec74-4f50-a22a-f10e6ba67601",
   "metadata": {},
   "source": [
    "<p>Save your trained model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1aae8-4af7-4623-a993-9e03fc8cb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fashion_mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f97ffc-4332-4017-a88d-034f9cd57b77",
   "metadata": {},
   "source": [
    "<p>Load a saved model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331aff4-d5d9-4777-bd2e-a38a95fdbc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_batch(out_1=16, out_2=32, num_classes=10)\n",
    "model.load_state_dict(torch.load('fashion_mnist_cnn.pth'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54338619-05bb-4eaa-b381-ad9ff987e54e",
   "metadata": {},
   "source": [
    "<h2>Conclusion</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b755b0-34b3-42a0-a1de-9e8018721bf4",
   "metadata": {},
   "source": [
    "<p>In this project, we've:</p>\n",
    "<ol>\n",
    "    <li>Prepared the Fashion MNIST dataset</li>\n",
    "    <li>Built a CNN with batch normalization</li>\n",
    "    <li>Trained the model to classify fashion items</li>\n",
    "    <li>Evaluated its performance</li>\n",
    "    <li>Explored ways to improve the model</li>\n",
    "</ol>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
